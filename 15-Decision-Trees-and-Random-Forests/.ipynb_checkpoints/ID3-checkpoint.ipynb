{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aeb798b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4934489",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeNode(object):\n",
    "    def __init__(self, ids=None, children=[], entropy=0, depth=0):\n",
    "        self.ids = ids # index of data in this node\n",
    "        self.entropy = entropy # entropy, wil fill later\n",
    "        self.depth = depth # distance to root node\n",
    "        self.split_attribute = None # which attribute is chosen, it non-leaf\n",
    "        self.children = children # list of its child nodes\n",
    "        self.order = None # order of values of split_attribute in children\n",
    "        self.label = None # label of node if it is a leaf\n",
    "    \n",
    "    def set_properties(self, split_attribute, order):\n",
    "        self.split_attribute = split_attribute # split at which attributes\n",
    "        self.order = order # order of this node's children\n",
    "        \n",
    "    def set_label(self, label):\n",
    "        self.label = label # set label if the node is a leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e58233cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(freq):\n",
    "    # remove prob 0 \n",
    "    freq_0 = freq[np.array(freq).nonzero()[0]]\n",
    "    prob_0 = freq_0/float(freq_0.sum())\n",
    "    return -np.sum(prob_0*np.log(prob_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b11c65c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTreeID3(object):\n",
    "    def __init__(self, max_depth= 10, min_samples_split = 2, min_gain = 1e-4):\n",
    "        self.root = None\n",
    "        self.max_depth = max_depth \n",
    "        self.min_samples_split = min_samples_split \n",
    "        self.Ntrain = 0\n",
    "        self.min_gain = min_gain\n",
    "    \n",
    "    def fit(self, data, target):\n",
    "        self.Ntrain = data.count()[0]\n",
    "        self.data = data \n",
    "        self.attributes = list(data)\n",
    "        self.target = target \n",
    "        self.labels = target.unique()\n",
    "        \n",
    "        ids = range(self.Ntrain)\n",
    "        self.root = TreeNode(ids = ids, entropy = self._entropy(ids), depth = 0)\n",
    "        queue = [self.root]\n",
    "        while queue:\n",
    "            node = queue.pop()\n",
    "            if node.depth < self.max_depth or node.entropy < self.min_gain:\n",
    "                node.children = self._split(node)\n",
    "                if not node.children: #leaf node\n",
    "                    self._set_label(node)\n",
    "                queue += node.children\n",
    "            else:\n",
    "                self._set_label(node)\n",
    "                \n",
    "    def _entropy(self, ids):\n",
    "        # calculate entropy of a node with index ids\n",
    "        if len(ids) == 0: return 0\n",
    "        ids = [i+1 for i in ids] # panda series index starts from 1\n",
    "        freq = np.array(self.target[ids].value_counts())\n",
    "        return entropy(freq)\n",
    "\n",
    "    def _set_label(self, node):\n",
    "        # find label for a node if it is a leaf\n",
    "        # simply chose by major voting \n",
    "        target_ids = [i + 1 for i in node.ids]  # target is a series variable\n",
    "        node.set_label(self.target[target_ids].mode()[0]) # most frequent label\n",
    "    \n",
    "    def _split(self, node):\n",
    "        ids = node.ids \n",
    "        best_gain = 0\n",
    "        best_splits = []\n",
    "        best_attribute = None\n",
    "        order = None\n",
    "        sub_data = self.data.iloc[ids, :]\n",
    "        for i, att in enumerate(self.attributes):\n",
    "            values = self.data.iloc[ids, i].unique().tolist()\n",
    "            if len(values) == 1: continue # entropy = 0\n",
    "            splits = []\n",
    "            for val in values: \n",
    "                sub_ids = sub_data.index[sub_data[att] == val].tolist()\n",
    "                splits.append([sub_id-1 for sub_id in sub_ids])\n",
    "            # don't split if a node has too small number of points\n",
    "            if min(map(len, splits)) < self.min_samples_split: continue\n",
    "            # information gain\n",
    "            HxS= 0\n",
    "            for split in splits:\n",
    "                HxS += len(split)*self._entropy(split)/len(ids)\n",
    "            gain = node.entropy - HxS \n",
    "            if gain < self.min_gain: continue # stop if small gain \n",
    "            if gain > best_gain:\n",
    "                best_gain = gain \n",
    "                best_splits = splits\n",
    "                best_attribute = att\n",
    "                order = values\n",
    "        node.set_properties(best_attribute, order)\n",
    "        child_nodes = [TreeNode(ids = split,\n",
    "                     entropy = self._entropy(split), depth = node.depth + 1) for split in best_splits]\n",
    "        return child_nodes\n",
    "\n",
    "    def predict(self, new_data):\n",
    "        \"\"\"\n",
    "        :param new_data: a new dataframe, each row is a datapoint\n",
    "        :return: predicted labels for each row\n",
    "        \"\"\"\n",
    "        npoints = new_data.count()[0]\n",
    "        labels = [None]*npoints\n",
    "        for n in range(npoints):\n",
    "            x = new_data.iloc[n, :] # one point \n",
    "            # start from root and recursively travel if not meet a leaf \n",
    "            node = self.root\n",
    "            while node.children: \n",
    "                node = node.children[node.order.index(x[node.split_attribute])]\n",
    "            labels[n] = node.label\n",
    "            \n",
    "        return labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92b2a19c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no']\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('weather.csv', index_col = 0, parse_dates = True)\n",
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]\n",
    "tree = DecisionTreeID3(max_depth = 3, min_samples_split = 2)\n",
    "tree.fit(X, y)\n",
    "print(tree.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbf5d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
